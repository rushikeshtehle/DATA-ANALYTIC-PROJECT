import pandas as pd
import numpy as np
import matplotlib.pyplot as ply
import seaborn as sns
import re
import string
import nltk
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline


df = pd.read_csv('Twitter Sentiments.csv')
df.head()


df.info()


def remove_pattern (input_txt,pattern):
   r= re.findall(pattern, input_txt)
   for word in  r:
       input_txt = re.sub(word,"",input_txt)
   return input_txt
df.head()


df['clean_tweet'] = np.vectorize(remove_pattern) (df['tweet'],"g[\w]*")
df.head()


df['clean_tweet'] = df['clean_tweet'].str.replace("[^a-zA-Z#]","")
df.head()


df['clean_tweet']=df['clean_tweet'].apply(lambda x: "".join([w for w in x.split() if len(w)>3]))
df.head()


tokenized_tweet = df['clean_tweet'].apply (lambda x: x.split())
tokenized_tweet.head()


from nltk.stem.porter import PorterStemmer
stemmer = PorterStemmer()

tokenized_tweet = tokenized_tweet.apply (lambda sentence: [stemmer. stem (word) for word in sentence ])
tokenized_tweet.head()


for i in range (len(tokenized_tweet)):
    tokenized_tweet[i]="".join(tokenized_tweet[i])

df['clean_tweet'] = tokenized_tweet
df.head()


all_words = "".join ([sentence for sentence in df['clean_tweet']])

from wordcloud import WordCloud
wordcloud = WordCloud(width = 800, height=500, random_state=42, max_font_size=100).generate(all_words)

import matplotlib.pyplot as plt
plt.figure (figsize = (15,8))
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.show()


all_words = "".join ([sentence for sentence in df['clean_tweet'] [df['label']==0]])

wordcloud = WordCloud(width = 800, height=500, random_state=42, max_font_size=100).generate(all_words)

import matplotlib.pyplot as plt
plt.figure (figsize = (15,8))
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.show()


all_words = "".join ([sentence for sentence in df['clean_tweet'] [df['label']==1]])

wordcloud = WordCloud(width = 800, height=500, random_state=42, max_font_size=100).generate(all_words)

import matplotlib.pyplot as plt
plt.figure (figsize = (15,8))
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.show()


def hastag_extract (tweets):
    hastags = []

    for tweet in tweets:
        ht = re.findall (r"#(w\+)",tweet)
        hastags.append (ht)
    return hastags


ht_positive = hastag_extract(df['clean_tweet'][df['label'] ==0])

ht_negative = hastag_extract(df['clean_tweet'][df['label'] ==1])


ht_negative[:5]


ht_positive[:5]


ht_positive = sum (ht_positive,[])
ht_negative = sum (ht_negative,[])

ht_positive[:5]


freq = nltk.FreqDist(ht_positive)
d = pd.DataFrame ({'hastag': list(freq.keys()),
                  'count': list(freq.values())})
d.head()


d = d.nlargest (columns = 'count', n = 10)
plt.figure (figsize =(15,9))
sns.barplot( x='Hastag', y='count',data=d)
plt.show()


from sklearn.feature_extraction.text import CountVectorizer
bow_vectorizer = CountVectorizer (max_df=0.90, min_df=2, max_features=1000, stop_words='english')
bow = bow_vectorizer.fit_transform(df['clean_tweet'])


bow[0].toarray()


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42,test_size=0.25)


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score,accuracy_score


model1 = LogisticRegression()
model1.fit(x_train,y_train)


pred = model1.predict(x_test)
f1_score(y_test,pred)


accuracy_score(y_test,pred)


pred_prob = model1.predict_proba(x_test)
pred = pred_prob[:,1] >=0.3
pred = pred.astype(np.int_)

f1_score(y_test,pred)


accuracy_score(y_test,pred)


pred_prob[0]


pred_prob[0][1] >= 0.3








































